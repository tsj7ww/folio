{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid19 Data Analysis\n",
    "\n",
    "#### Overview\n",
    "...\n",
    "\n",
    "#### Data Sources\n",
    "* **Covid19**\n",
    "    * [Johns Hopkins University - Covid19 Data](https://github.com/CSSEGISandData/COVID-19)\n",
    "* **Demographics**\n",
    "    * [US Census Bureau - 2019 Annual Social and Economic Supplements](https://www.census.gov/content/census/en/data/datasets/2019/demo/cps/cps-asec-2019.html)\n",
    "    * [US Census Bureau - 2019 Current Population Survey](https://www.census.gov/content/census/en/data/datasets/2019/demo/cps/cps-basic-2019.html)\n",
    "    * [US Census Bureau - International Demographic Overview](https://www.census.gov/data-tools/demo/idb/region.php?T=13&RT=0&A=both&Y=2020&C=&R=1)\n",
    "    * [The World Bank - World Development Indicators](https://datacatalog.worldbank.org/dataset/world-development-indicators)\n",
    "    * [The World Bank - Population Estimates and Projections](https://datacatalog.worldbank.org/dataset/population-estimates-and-projections)\n",
    "    * [IMF - World Economic Outlook](https://www.imf.org/external/pubs/ft/weo/2020/01/weodata/download.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import itertools\n",
    "import subprocess\n",
    "import os\n",
    "from io import StringIO\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CONFIG(env):\n",
    "    \"\"\"\"\"\"\n",
    "    pid = 'analysis-covid19'\n",
    "    now = datetime.datetime.now()\n",
    "    cwd = os.getcwd()\n",
    "    f_in = os.path.join(cwd,'in')\n",
    "    f_out = os.path.join(cwd,'out')\n",
    "    cov = os.path.join(f_in,'covid')\n",
    "    \n",
    "    cfg = {\n",
    "        'paths': {\n",
    "            'covid': cov\n",
    "            ,'f_in': f_in\n",
    "            ,'f_out': f_out\n",
    "            ,'eda': os.path.join(cwd,'eda')\n",
    "            ,'pq': os.path.join(f_out)\n",
    "        }\n",
    "        ,'jhu-refresh': os.path.join(cwd,'jhu-refresh.sh')\n",
    "        ,'jhu-dly': { # johns hopkins university - global daily\n",
    "            'path': os.path.join(cov,'jhu','csse-dly','{DATE}.csv')\n",
    "            ,'dates': {\n",
    "                'start': datetime.date(2020,4,12)\n",
    "                ,'end': datetime.date(2020,9,30)\n",
    "            }\n",
    "        }\n",
    "        ,'jhu-dly-us': { # johns hopkins university - us daily\n",
    "            'path': os.path.join(cov,'jhu','csse-dly-us','{DATE}.csv')\n",
    "            ,'dates': {\n",
    "                'start': datetime.date(2020,4,12)\n",
    "                ,'end': datetime.date(2020,9,30)\n",
    "            }\n",
    "        }\n",
    "        ,'jhu-ts': { # johns hopkins university - timeseries\n",
    "            'base': os.path.join(cov,'jhu','csse-ts','time_series_covid19_{STATUS}_{REGION}.csv')\n",
    "            ,'options': {\n",
    "                'status': ['confirmed','deaths','recovered']\n",
    "                ,'region': ['global','US']\n",
    "            }\n",
    "            ,'errata': os.path.join(cov,'jhu','csse-ts','Errata.csv')\n",
    "        }\n",
    "        ,'jhu-who-ts': { # johns hopkins university - WHO timeseries\n",
    "            'path': os.path.join(cov,'jhu','who-ts','who_covid_19_sit_rep_time_series.csv')\n",
    "        }\n",
    "        ,'jhu-fips': { # johns hopkins university - fips lkup table\n",
    "            'path': os.path.join(cov,'jhu','csse-fips-lkup.csv')\n",
    "        }\n",
    "        ,'cb-acs': { # census bureau - american community survey\n",
    "            'base': 'https://api.census.gov/data/{YEAR}/pep/charage?get={FIELDS}&for=state:{STATES}'\n",
    "            ,'query': {\n",
    "                'years': ['2019']\n",
    "                ,'fields': ','.join(['POP','NAME'])\n",
    "                ,'states': ','.join(['*'])\n",
    "            }\n",
    "        }\n",
    "        ,'cb-idb': { # census bureau - international database\n",
    "            'base': 'https://api.census.gov/data/timeseries/idb/1year?time={YEAR}&get={FIELDS}'\n",
    "            ,'query': {\n",
    "                'years': ['2019']\n",
    "                ,'fields': ['AREA_KM2','NAME','AGE','POP','FIPS','SEX']\n",
    "            }\n",
    "        }\n",
    "#         ,'wb-dev': {\n",
    "#             'base'\n",
    "#         }\n",
    "#         ,'wb-pop': {\n",
    "            \n",
    "#         }\n",
    "#         ,'imf-econ': {\n",
    "            \n",
    "#         }\n",
    "    }\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOGGER(env):\n",
    "    \"\"\"\"\"\"\n",
    "    fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    formatter = logging.Formatter(fmt)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    if env=='dev':\n",
    "        level = logging.DEBUG\n",
    "        feed = sys.stdout\n",
    "    elif env=='qa':\n",
    "        level = logging.INFO\n",
    "        feed = StringIO()\n",
    "    elif env=='prod':\n",
    "        level = logging.WARNING\n",
    "        feed = StringIO()\n",
    "    else:\n",
    "        raise Exception('Unknown environment.')\n",
    "\n",
    "    handler = logging.StreamHandler(feed)\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    return logger,feed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JHU_DLY(base,start,end):\n",
    "    \"\"\"\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    file_dt = '%m-%d-%Y'\n",
    "    data_dt = '%Y-%m-%d'\n",
    "    \n",
    "    df = pd.DataFrame(None)\n",
    "    errs = []\n",
    "    \n",
    "    for i in range((end-start).days+1):\n",
    "        dt = (start+datetime.timedelta(days=i))\n",
    "        try:\n",
    "            if df.empty:\n",
    "                df = pd.read_csv(base.format(DATE=dt.strftime(file_dt)),header=0).assign(DATA_DT=dt.strftime(data_dt))\n",
    "            else:\n",
    "                df = df.append(pd.read_csv(base.format(DATE=dt.strftime(file_dt)),header=0).assign(DATA_DT=dt.strftime(data_dt)))\n",
    "        except Exception as e:\n",
    "            errs.append((dt,str(e)))\n",
    "   \n",
    "    df = CLEANER(df)\n",
    "                               \n",
    "    return df,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CB_ACS(base,years,fields,states):\n",
    "    \"\"\"\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    df = pd.DataFrame(None)\n",
    "    errs = []\n",
    "    \n",
    "    for yr in years:\n",
    "        url = base.format(YEAR=yr,FIELDS=fields,STATES=states)\n",
    "        response = rq.get(url)\n",
    "        if response.status_code == requests.codes.ok:\n",
    "            data = response.json()\n",
    "            if df.empty:\n",
    "                df = pd.DataFrame(data[1:],columns=data[0])\n",
    "            else:\n",
    "                df.append(pd.DataFrame(data[1:],columns=data[0]))\n",
    "        else:\n",
    "            errs.append(url)\n",
    "    \n",
    "    df = CLEANER(df)\n",
    "    \n",
    "    return df,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DB_IDB(base,years,fields):\n",
    "    \"\"\"\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    df = pd.DataFrame(None)\n",
    "    errs = []\n",
    "    \n",
    "    for yr in years:\n",
    "        url = base.format(YEAR=yr,FIELDS=','.join(fields))\n",
    "        response = rq.get(url)\n",
    "        if response.status_code == requests.codes.ok:\n",
    "            data = response.json()\n",
    "            if df.empty:\n",
    "                df = pd.DataFrame(data[1:],columns=data[0])\n",
    "            else:\n",
    "                df.append(pd.DataFrame(data[1:],columns=data[0]))\n",
    "        else:\n",
    "            errs.append(url)\n",
    "    \n",
    "    df = CLEANER(df)\n",
    "    \n",
    "    return df,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLEANER(df):\n",
    "    \"\"\"\"\"\"\n",
    "    def COLUMN(x):\n",
    "        if not x[0].isalnum():\n",
    "            x=x[1:]\n",
    "        if not x[-1].isalnum():\n",
    "            x=x[:-1]\n",
    "        return x.upper()\n",
    "\n",
    "    df.columns = map(lambda x: COLUMN(x), df.columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA(df,f_out,n=100):\n",
    "    \"\"\"\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    name = os.path.basename(f_out).split('.')[0]\n",
    "    lb = '\\n'\n",
    "    lblb = '\\n\\n'\n",
    "    \n",
    "    # columns & types\n",
    "    content = '# EDA - {} Files {}'.format(os.path.basename(name).upper(),lblb)\n",
    "    content+='#### Column Name [IDX] -  Dtype (Head / Tail) \\n'\n",
    "    dtypes = df.dtypes.to_dict()\n",
    "    head = df.head(1).T.iloc[:,0].to_list() # to_dict() - head.get(j)\n",
    "    tail = df.tail(1).T.iloc[:,0].to_list() # to_dict() - tail.get(j)\n",
    "    for i,j in enumerate(df.columns):\n",
    "        content+='- **{}** [{}] - {} ({} / {}) {}'.format(j, i, dtypes.get(j), head[i], tail[i], lb)\n",
    "    \n",
    "    # html\n",
    "    content+='{}#### Head / Tail [n={}] Sample {}'.format(lb+lblb,n,lblb)\n",
    "    content+=(df.head(n).append(df.tail(n)).to_html(None,index=True,header=True))\n",
    "    \n",
    "    with open(f_out,'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PARQUET(df,f_out):\n",
    "    \"\"\"\"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    df.to_parquet(f_out,engine='pyarrow',index=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "# def MAIN():\n",
    "#     \"\"\"\"\"\"\n",
    "    env = 'dev'\n",
    "    LOG,FEED = LOGGER(env)\n",
    "    CFG = CONFIG(env)\n",
    "    \n",
    "    sample_size = 20\n",
    "    refresh = False\n",
    "    if refresh:\n",
    "        out = subprocess.run(['sh', CFG['jhu-refresh']]).returncode\n",
    "        if out == 0:\n",
    "            pass\n",
    "        elif out == 1:\n",
    "            raise Exception('Error while refreshing covid19 data.')\n",
    "        elif out == 127:\n",
    "            raise Exception('File not found.')\n",
    "        else:\n",
    "            raise Exception('Unknown shell out code: {}'.format(out))\n",
    "        \n",
    "            \n",
    "    try:\n",
    "        segment = 'covid'\n",
    "        src = 'jhu'\n",
    "        covid = {\n",
    "            'jhu-dly': JHU_DLY(CFG['jhu-dly']['path'],**CFG['jhu-dly']['dates'])[0],\n",
    "            'jhu-dly-us': JHU_DLY(CFG['jhu-dly-us']['path'],**CFG['jhu-dly-us']['dates'])[0],\n",
    "            'jhu-ts': pd.read_csv(CFG['jhu-ts']['base'].format(STATUS='confirmed',REGION='US'),header=0),\n",
    "            'jhu-who-ts': pd.read_csv(CFG['jhu-who-ts']['path'],header=0),\n",
    "            'jhu-ts-err': pd.read_csv(CFG['jhu-ts']['errata'],header=0),\n",
    "            'jhu-fips': pd.read_csv(CFG['jhu-fips']['path'],header=0),\n",
    "        }\n",
    "        for fname,df in covid.items():\n",
    "            # clean df\n",
    "            df = CLEANER(df)\n",
    "            # md eda file\n",
    "            fpath = os.path.join(CFG['paths']['eda'],'{}-{}.md'.format(segment,fname))\n",
    "            EDA(df,fpath,n=sample_size)\n",
    "            # parquet clean file\n",
    "            fpath = os.path.join(CFG['paths']['pq'],segment,'{}-{}.parquet.gzip'.format(segment,fname))\n",
    "            PARQUET(df,fpath)\n",
    "    \n",
    "    except Exception as e:\n",
    "        LOG.critical(str(e))\n",
    "        raise\n",
    "    \n",
    "    try:\n",
    "        segment = 'demo'\n",
    "        for fname in ['cb-acs','cb-idb']:\n",
    "            if fname == 'cb-acs':\n",
    "                df,errs = CB_ACS(CFG[fname]['base'],**CFG[fname]['query'])\n",
    "            elif name == 'cb-idb':\n",
    "                df,errs = DB_IDB(CFG[fname]['base'],**CFG[fname]['query'])\n",
    "            else:\n",
    "                raise Exception('Unknown file name.')\n",
    "            # md eda file\n",
    "            fpath = os.path.join(CFG['paths']['eda'],'{}-{}.md'.format(segment,fname))\n",
    "            EDA(df,fpath,n=sample_size)\n",
    "            # parquet clean file\n",
    "            fpath = os.path.join(CFG['paths']['pq'],segment,'{}-{}.parquet.gzip'.format(segment,fname))\n",
    "            PARQUET(df,fpath)\n",
    "    \n",
    "    except Exception as e:\n",
    "        LOG.critical(str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
